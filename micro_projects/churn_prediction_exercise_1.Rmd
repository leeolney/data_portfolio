---
title: "Customer Churn Prediction Exercise"
output: html_notebook
---

#### Dataset: [Credit card customers](https://www.kaggle.com/sakshigoyal7/credit-card-customers/tasks?taskId=2729)


#### Load packages
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(skimr)
library(Hmisc)
library(ggsci)
library(caret)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(caret)
library(xgboost)
library(pscl)
library(pROC)
```

#### Import data
```{r}
df = read.csv("BankChurners.csv", header=TRUE)
head(df)
#delete naive bayes columns
df = df[,2:21]
```

```{r}
dim(df)
colnames(df)
```

#### Target variable
```{r}
Hmisc::describe(df$Attrition_Flag)
#convert target variable to numeric 
df$label= ifelse(df$Attrition_Flag =="Attrited Customer","1","0")
df$label = as.factor(df$label)
Hmisc::describe(df$label)
#drop attrition flag 
df = subset(df, select = -c(Attrition_Flag))
```

* For the purpose of this exercise, Attrited Customer and Existing Customer classes are releveled to 1 and 0 respectively. 
* Out of 10127 obs, 1627 (16.1%) are attrited customers suggesting an imbalanced dataset.

```{r}
#summary
df = df %>% mutate_at(vars(label, Gender,Education_Level,Income_Category,Marital_Status,Card_Category),list(factor))
skim(df)
```

#### Exploratory data analysis
```{r}
p1 = df %>% group_by(label,Contacts_Count_12_mon) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=Contacts_Count_12_mon, y=prop,fill=label)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom")
p2 = df %>% group_by(label,Months_Inactive_12_mon) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=Months_Inactive_12_mon, y=prop,fill=label)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom")
grid.arrange(p1,p2,ncol=2,nrow=1)
```

* Contacts_Count_12_mon: customers with 3 or more contacts count in the past 12 months have a higher proportion of attrition
* Months_Inactive_12_mon: customers with 3 or more inactive months in the past 12 months have a higher proportion of attrition 

```{r}
p3 = df %>% group_by(label,Total_Relationship_Count) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=Total_Relationship_Count, y=prop,fill=label)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom") 
p4 = df %>% group_by(label,Dependent_count) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=Dependent_count, y=prop,fill=label)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom")
grid.arrange(p3,p4,ncol=2,nrow=1)
```

* Total_Relationship_Count: customers with 3 or less total relationship count has a higher proportion of attrition
* Dependent_count: customers with 3 or more dependents have a higher proportion of attrition 

```{r}
p5 = df %>% group_by(Gender,label) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=label, y=prop,fill=Gender)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom")
p6 = df %>% group_by(label,Education_Level) %>% tally() %>% mutate(prop=n/sum(n)) %>% ggplot(aes(x=Education_Level, y=prop,fill=label)) + geom_col(position="dodge") + scale_fill_jama() + labs(y="proportion") + theme_light() + theme(legend.position="bottom") + coord_flip()
grid.arrange(p5,p6,ncol=2,nrow=1)
```

* Gender: Female has a higher proportion of attrition compared to males. 
* Education_Level: The attrition class has a higher proportion of doctorate, post-graduate and unknown education level compared to the existing customer class.

Density plots (inspired by [Who's gonna churn?](https://www.kaggle.com/virosky/who-s-gonna-churn) by Carmine Minichini)
```{r}
p7 = df %>% ggplot(aes(x=Total_Trans_Ct, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light() 
p8 = df %>% ggplot(aes(x=Total_Ct_Chng_Q4_Q1, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light()
p9 = df %>% ggplot(aes(x=Total_Revolving_Bal, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light()
p10 = df %>% ggplot(aes(x=Avg_Utilization_Ratio, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light()
p11 = df %>% ggplot(aes(x=Total_Trans_Amt, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light()
p12 = df %>% ggplot(aes(x=Credit_Limit, fill=label)) + geom_density(alpha=0.6) + scale_fill_jama() + theme_light()
grid.arrange(p7,p8,ncol=1,nrow=2)
grid.arrange(p9,p10,ncol=1,nrow=2)
grid.arrange(p11,p12,ncol=1,nrow=2)
```

* The attrition class has a lower total transaction count, total count change, total revolving balance, average utilization ratio and total transactions amount compared to the existing customers class, as expected.

#### Feature selection
```{r}
#check correlation of all numeric variables
df_num = select_if(df,is.numeric)
df_num = data.frame(lapply(df_num, function(x) as.numeric(as.character(x))))
res=cor(df_num)
corrplot(res, type="upper", tl.col="#636363",tl.cex=0.5 )
```
* Avg_Open_To_Buy is highly correlated to Credit_Limit
* Total_Trans amount is highly correlated to Total_Trans_Amt
* Total_Amt_Chng_Q4_Q1 is correlated to Total_Ct_Cng_Q4_Q1
* Avg_Utilization_Ratio is correlated to Avg_Open_To_BUy, Total_Revolving_Bal and Credit_Limit

```{r}
#drop Months_on_book,Total_Trans_Amt, Total_Amt_Chng_Q4_Q1, Avg_Utilization_Ratio
df1 = df %>% select(-c(Months_on_book,Total_Trans_Amt, Total_Amt_Chng_Q4_Q1, Avg_Utilization_Ratio, Avg_Open_To_Buy))
dim(df1)
```

```{r}
#check correlation after dropping variables
df1_num = select_if(df1,is.numeric)
df1_num = data.frame(lapply(df1_num, function(x) as.numeric(as.character(x))))
res2=cor(df1_num)
corrplot(res2, type="lower", tl.col="#636363",tl.cex=0.5 )
```

#### Test and train set
```{r}
trainIndex <- createDataPartition(df1$label, p = .75,list=FALSE)
training <- df1[trainIndex,]
testing <- df1[-trainIndex,]
```

```{r}
Hmisc::describe(training$label)
Hmisc::describe(testing$label)
```


#### Logistic regression

```{r}
model1= glm(label ~., data=training, family = "binomial")
summary(model1) 
pR2(model1)  
anova(model1, test= "Chisq")
```

* 8 variables (Gender, Total_Relationship_Count, Months_Inactive_12_mon, Contacts_Count_12_mon, Credit_Limit, Total_Revolving_Bal, Total_Trans_Ct and Total_Ct_Chng_Q4_Q1) are significant variables in predicting customer churn for credit card services. 
  + Analysis of deviance table shows that Total_Trans_Ct has most significant variable. 
* Logistic regression model suggests that: 
  + The log odds of a male customer churning is 0.7 lower than female. 
  + For one unit increase in dependent count, the log odds of the customer churning increases by 0.1.
  + Versus income category 120K+, the 40K-60K category decreases the log odds of the customer churning by 0.5.
  + Versus the blue card category, gold category increases the log odds of the customer churning by 1.4
  + For one unit increase in total relationship count, the log odds of the customer churning decreases by 0.5. 
  + For one unit increase in months inactive in the last 12 months, the log odds of the customer churning increases by 0.5.
  + For one unit increase in total revolving balance, the log odds of the customer churning decreases by 0.0009. 
  + For one unit increase in total transaction count, the log odds of the customer churning decreases by 0.07.
  + For one unit increase Change in Transaction Count (Q4 over Q1) , the log odds of the customer churning decreases by 2.8.


```{r}
prob=predict(model1,testing,type="response")
prob1=rep(0,2531)
prob1[prob>0.2]=1
cmlr = confusionMatrix(as.factor(prob1), testing$label, positive="1")
cmlr
round(cmlr$byClass["F1"], 4)
roc_lr2 = roc(testing$label, prob1, plot=TRUE, print.auc=TRUE)
```
* 319 out of 406 positive instances were predicted correctly (recall of 0.786) with logistic regression (probability value 0.2)

#### Decision tree
```{r}
mt = rpart(label ~., data = training, method = "class")
plotcp(mt)
```

```{r}
mt_prune = prune(mt,cp=0.036)
fancyRpartPlot(mt_prune)
printcp(mt_prune)
mt_prune$variable.importance
```

```{r}
tree.p = predict(mt_prune, testing, type = "class")
cmt = confusionMatrix(tree.p, testing$label, positive ="1")
cmt
round(cmt$byClass["F1"], 4)
testing$tp1= tree.p
roc_t= roc(response= testing$label, predictor = factor(testing$tp1, ordered=TRUE), plot=TRUE, print.auc=TRUE)
```

*249 out of 486 positive instances were predicted correctly (recall of 0.613) with classification tree. 

#### Random forest 
```{r}
trControl <- trainControl(method = "cv",
    number = 10,
    search = "grid")
```

```{r}
set.seed(1234)
rf1 = train(label ~ .,data = training,method="rf",metric ="Accuracy",trControl = trControl)
print(rf1)
```

```{r}
plot(rf1)
varImp(rf1)
```
```{r}
rfpred = predict(rf1, testing)
cmrf = confusionMatrix(rfpred, testing$label,positive="1")
cmrf
round(cmrf$byClass["F1"], 4)
testing$rfp= rfpred
roc_rf= roc(response= testing$label, predictor = factor(testing$rfp, ordered=TRUE), plot=TRUE, print.auc=TRUE)
```
* 277 out of 486 positive instances were predicted correctly (recall of 0.682) with random forest. 


#### XGBoost
XGBoost code reference: [Who's gonna churn?](https://www.kaggle.com/virosky/who-s-gonna-churn) by Carmine Minichini   

```{r}
target_column = df1$label
data =  df1 %>% select(-label)
dmy = dummyVars(" ~ .", data = data)
train_data = data.frame(predict(dmy, newdata = data))
data <- cbind(train_data,target_column)
names(data)[33] <- 'label'
```

```{r}
trainIndex <- createDataPartition(data$label,p=0.75,list=FALSE)
data_train <- data[trainIndex,]
data_test <-  data[-trainIndex,]
```

```{r}
grid_train = data_train
levels(grid_train$label) <- c("X0","X1")
#grid parameters
xgb_grid_1 = expand.grid(
    nrounds = 10,
    eta = seq(2,10,by=1)/10,
    max_depth = c(6, 8, 10),
    gamma = 0,
    subsample = c(0.5, 0.75, 1),
    min_child_weight = c(1,2) ,
    colsample_bytree = c(0.3,0.5)
  )
# pack the training control parameters
  xgb_trcontrol_1 = trainControl(
    method = "cv",
    number = 2,
    search='grid',
    verboseIter = FALSE,
    returnData = TRUE,
    returnResamp = "all", # save losses across all models
    classProbs = TRUE, # set to TRUE for AUC to be computed
    summaryFunction = prSummary, # probability summary(AUC)
    allowParallel = TRUE,
  )
```

```{r}
xgb_train_1 = train(
    x = as.matrix(grid_train %>% select(-label)),
    y = factor(grid_train$label),
    trControl = xgb_trcontrol_1,
    tuneGrid = xgb_grid_1,
    method = "xgbTree",
    metric= 'Recall'
  )
```

```{r}
best_tune <- xgb_train_1$bestTune
results <- xgb_train_1$results
trained_model <- xgb_train_1
cat(paste("",
            paste('With a recall of:',results[rownames(best_tune),"Recall"]),
            'Best GRIDSEARCH Hyperparameters:',
            '',
            sep='\n\n'))
  
rownames(best_tune) <- 'Value'
print(t(best_tune))
```
```{r}
#out dataframe
gridresults = results
best_tune = best_tune
train_data = data_train
test_data = data_test
```


```{r}
#best hyperparameters from gridsearch
best_tune <- best_tune
#train
data_train <- train_data %>% select(-label)
label_train <- train_data$label
#test
data_test <- test_data %>% select(-label)
label_test <- test_data$label
# as matrix
data_train <- as.matrix(data_train)
data_test <- as.matrix(data_test)
# as numeric
label_train <- as.numeric(label_train)
label_test <- as.numeric(label_test)
#relevel
label_train= ifelse(label_train>1,1,0)
label_test= ifelse(label_test>1,1,0)

```


```{r}
#XGB matrix
dtrain <-  xgb.DMatrix(data_train,label=label_train)
dtest <- xgb.DMatrix(data_test,label=label_test)
```

```{r}
#XGB model
 model <- xgboost(data= dtrain, 
                   objective = "binary:logistic",
                   max_depth = best_tune$max_depth,
                   nrounds=100,
                   colsample_bytree = best_tune$colsample_bytree,
                   gamma = best_tune$gamma,
                   min_child_weight = best_tune$min_child_weight,
                   eta = best_tune$eta, 
                   subsample = best_tune$subsample,
                   print_every_n = 20,
                   scale_pos_weight=5.22,
                   max_delta_step=1,
                   eval_metric='aucpr',
                   verbose=1,
                   nthread = 4)

cv  <-  xgb.cv(data = dtrain, 
                 nround = 50, 
                 print_every_n= 10,
                 verbose = TRUE,
                 metrics = list("aucpr"),
                 nfold = 5, 
                 nthread = 4,
                 objective = "binary:logistic",
                 prediction=F)

out <- list(data_train = data_train,
              dtest = dtest,
              label_test = label_test,
              model = model)
```

```{r}
data_train <- data_train
pred <- predict(model,dtest)
prediction <- as.numeric(pred > 0.5)
cm <- confusionMatrix(factor(prediction),factor(label_test),positive="1")
cm
round(cm$byClass["F1"], 4)
roc.curve = roc(response = label_test,
                  predictor = prediction,
                  levels=c(0, 1),quiet = T) 
plot(roc.curve,print.auc=TRUE)
```
 *334 out of 486 positive instances are predicted correctly with XGB (0.823)
 
```{r}
importance_matrix <- xgb.importance(colnames(data_train), model = model)
  xgb.plot.importance(importance_matrix,
                      top_n=10,
                      main='Features Importance',
                      measure = 'Frequency')
```

#### Summary of exercise 

|                     | Recall | AUC   | F1 Score |
|---------------------|--------|-------|----------|
| Logistic regression | 0.786  | 0.833 | 0.651    |
| Decision tree       | 0.613  | 0.786 | 0.672    |
| Random Forest       | 0.682  | 0.83  | 0.757    |
| XGBoost             | 0.823  | 0.879 | 0.763    |

 

